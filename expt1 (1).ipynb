{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09bc026-cbc1-4e91-a57e-589915ee78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (first 5 rows):\n",
      "    Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes \n",
      "\n",
      "Dataset Shape: (10, 4)\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 452.0+ bytes\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "        Country        Age        Salary Purchased\n",
      "count       10   9.000000      9.000000        10\n",
      "unique       3        NaN           NaN         2\n",
      "top     France        NaN           NaN        No\n",
      "freq         4        NaN           NaN         5\n",
      "mean       NaN  38.777778  63777.777778       NaN\n",
      "std        NaN   7.693793  12265.579662       NaN\n",
      "min        NaN  27.000000  48000.000000       NaN\n",
      "25%        NaN  35.000000  54000.000000       NaN\n",
      "50%        NaN  38.000000  61000.000000       NaN\n",
      "75%        NaN  44.000000  72000.000000       NaN\n",
      "max        NaN  50.000000  83000.000000       NaN\n",
      "\n",
      "After Handling Missing Values:\n",
      "    Country   Age        Salary Purchased\n",
      "0   France  44.0  72000.000000        No\n",
      "1    Spain  27.0  48000.000000       Yes\n",
      "2  Germany  30.0  54000.000000        No\n",
      "3    Spain  38.0  61000.000000        No\n",
      "4  Germany  40.0  63777.777778       Yes\n",
      "\n",
      "After Encoding Categorical Data:\n",
      "    Country   Age        Salary  Purchased\n",
      "0        0  44.0  72000.000000          0\n",
      "1        2  27.0  48000.000000          1\n",
      "2        1  30.0  54000.000000          0\n",
      "3        2  38.0  61000.000000          0\n",
      "4        1  40.0  63777.777778          1\n",
      "\n",
      "Min-Max Scaler Result (first 5 rows):\n",
      "    Country       Age    Salary  Purchased\n",
      "0      0.0  0.739130  0.685714        0.0\n",
      "1      1.0  0.000000  0.000000        1.0\n",
      "2      0.5  0.130435  0.171429        0.0\n",
      "3      1.0  0.478261  0.371429        0.0\n",
      "4      0.5  0.565217  0.450794        1.0\n",
      "\n",
      "Standard Scaler Result (first 5 rows):\n",
      "     Country       Age        Salary  Purchased\n",
      "0 -1.083473  0.758874  7.494733e-01       -1.0\n",
      "1  1.324244 -1.711504 -1.438178e+00        1.0\n",
      "2  0.120386 -1.275555 -8.912655e-01       -1.0\n",
      "3  1.324244 -0.113024 -2.532004e-01       -1.0\n",
      "4  0.120386  0.177609  6.632192e-16        1.0\n",
      "\n",
      "Robust Scaler Result (first 5 rows):\n",
      "     Country       Age    Salary  Purchased\n",
      "0 -0.571429  0.748148  0.610229       -0.5\n",
      "1  0.571429 -1.518519 -0.913580        0.5\n",
      "2  0.000000 -1.118519 -0.532628       -0.5\n",
      "3  0.571429 -0.051852 -0.088183       -0.5\n",
      "4  0.000000  0.214815  0.088183        0.5\n",
      "\n",
      "Max-Abs Scaler Result (first 5 rows):\n",
      "    Country   Age    Salary  Purchased\n",
      "0      0.0  0.88  0.867470        0.0\n",
      "1      1.0  0.54  0.578313        1.0\n",
      "2      0.5  0.60  0.650602        0.0\n",
      "3      1.0  0.76  0.734940        0.0\n",
      "4      0.5  0.80  0.768407        1.0\n",
      "\n",
      "Dataset after removing outliers (shape): (10, 4)\n",
      "\n",
      "Training set shape: (8, 3)\n",
      "Testing set shape: (2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyash\\AppData\\Local\\Temp\\ipykernel_7792\\3860667095.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "C:\\Users\\gyash\\AppData\\Local\\Temp\\ipykernel_7792\\3860667095.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries and load dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Data.csv\") \n",
    "print(\"Original Data (first 5 rows):\\n\", df.head(), \"\\n\")\n",
    "\n",
    "# Step 2: Explore dataset \n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe(include=\"all\"))\n",
    "\n",
    "# Step 3: Handle Missing Values \n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\nAfter Handling Missing Values:\\n\", df.head())\n",
    "\n",
    "# Step 4: Encode Categorical Variables\n",
    "encoder = LabelEncoder()\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "print(\"\\nAfter Encoding Categorical Data:\\n\", df.head())\n",
    "\n",
    "# Step 5: Feature Scaling \n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "scalers = {\n",
    "    \"Min-Max Scaler\": MinMaxScaler(),\n",
    "    \"Standard Scaler\": StandardScaler(),\n",
    "    \"Robust Scaler\": RobustScaler(),\n",
    "    \"Max-Abs Scaler\": MaxAbsScaler()\n",
    "}\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    scaled = scaler.fit_transform(df[numeric_cols])\n",
    "    scaled_df = pd.DataFrame(scaled, columns=numeric_cols)\n",
    "    print(f\"\\n{name} Result (first 5 rows):\\n\", scaled_df.head())\n",
    "\n",
    "# Step 6: Handle Outliers \n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_outlier_removed = df[~((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"\\nDataset after removing outliers (shape):\", df_outlier_removed.shape)\n",
    "\n",
    "# Step 7 : Split Dataset Into Training, Evaluation and Validation Sets \n",
    "X = df_outlier_removed.drop(df_outlier_removed.columns[-1], axis=1)   # features\n",
    "y = df_outlier_removed[df_outlier_removed.columns[-1]]               \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7353f6b-73e7-44f3-983e-f430745b5d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
